# AI Interaction Personalization Technology Using Structured Data

**DEFENSIVE PUBLICATION**

This publication is a defensive publication intended to prevent patenting of the described technology by any individuals or organizations. The project was under CC0 1.0 Universal until April 12, 2025, and is now licensed under the MIT License (see LICENSE for details).

## Notice for Forkers and Cloners

As of April 12, 2025, Personal Context Manager (PCM) has switched from CC0 1.0 Universal to the MIT License to ensure attribution while remaining open-source. If you forked or cloned PCM before this date (e.g., forkers: AxiMinds, brucewedding, DRanger666, sgwd), your copy remains under CC0 1.0 terms. However, if you pull in new updates from the main repo, the MIT License will apply to those portions, requiring attribution (see [LICENSE_CHANGE.md](https://github.com/mikhashev/personal-context-manager/blob/main/LICENSE_CHANGE.md) for details).

I’d love to collaborate! I’m currently working on features like Memoripy integration for memory decay (due April 30, 2025). If you’re interested in contributing or aligning your copy with the MIT License for future updates, please reach out via X (@mikeshev4enko) or email from my profile. Let’s work together to enhance PCM!

## About the Project

This technology solves a fundamental limitation of modern AI systems — the lack of long-term memory between sessions. The core principle involves transferring structured data with a mandatory instruction block that defines the rules for processing them.

## Key Features

- Comprehensive preservation of relevant context between sessions
- Support for various data formats (JSON, YAML, XML, graph structures)
- Choice of data storage location (local/cloud)
- Personalization management through instructions
- Significantly improved recommendation accuracy through contextual personalization
- Optimized context transfer for improved response times

## Self-Improving Context Framework

We've developed a framework that enables context structures to evolve and improve over time based on usage patterns, neural feedback, and effectiveness metrics. Key components include:

- **Self-improvement tracking** - Automatically identifies patterns in context effectiveness
- **Neural interface integration** - Framework for correlating brain activity with context performance using EEG devices
- **Context evolution analysis** - Tracks changes over time and recommends structural improvements
- **Instruction optimization** - Tests and adapts instruction blocks to improve AI responses

This framework takes personalization to the next level by enabling continuous adaptation based on real-world performance data.

> **Note:** While the neural interface integration framework is implemented in code, it has not yet been tested with actual EEG hardware devices. The integration with Muse, EMOTIV, and OpenBCI exists at the code level and is ready for testing with physical devices.

- [Implementation Code](self-improvement/README.md)
- [Framework Documentation](docs/self-improvement-framework.md)
- [Visual Diagrams](docs/self-improvement-diagrams.md)

## Future Benchmarking

We are currently developing a comprehensive benchmarking framework to quantify the performance improvements provided by PCM technology. Our preliminary testing indicates substantial benefits in several key areas:

- **Context preservation** between sessions compared to traditional approaches
- **Recommendation accuracy** enhancement through contextual personalization
- **Response time optimization** through efficient context transfer
- **Cognitive load reduction** with neural interface integration

We are committed to transparent and reproducible performance testing. A detailed benchmarking methodology and results will be published in Q2 2025, with all test cases and measurement tools made available as open-source resources. If you're interested in contributing to our benchmarking efforts, please see our [contributing guidelines](CONTRIBUTING.md).

## Documentation

Full technical description is available in [technical-description.md](docs/technical-description.md).
Quick start guide is available in [simple-guide.md](docs/simple-guide.md).

## Use Cases

### Self-Education

We've developed a specialized personal context template for enhancing self-education using AI systems. This implementation leverages the latest research in cognitive science and memory formation to create an optimized learning experience.

The template incorporates:
- Evidence-based learning strategies (active recall, spaced repetition)
- Neuroscience-informed approaches to memory formation
- Techniques to overcome AI limitations like context windows and hallucinations
- Personalized learning pathways based on cognitive strengths and preferences

Files:
- [Personal Context Template for Self-Education](use-cases/self-education/personal_context_self_education_template.json)
- [How to Use Personal Context Template for AI-Enhanced Learning](use-cases/self-education/README.md)

## MCP Model Context Protocol support

[Server for Personal Context Technology (PCT) using the Model Context Protocol (MCP)](https://github.com/mikhashev/pct-mcp-server)
It enables AI assistants like Claude to access and update your personalized context data, creating persistent memory between sessions.

## Ethical Principles

This project is intended exclusively for civilian purposes: improving education, healthcare, increasing productivity, and personalizing AI interaction. Please review the [ethical guidelines](ETHICAL_GUIDELINES.md) before use.

## Support the Project

If you would like to support further development and promotion of the technology, you can send a donation to the following addresses:

- Bitcoin: [bc1qfev88vx2yem48hfj04udjgn3938afg5yvdr92x]
- Ethereum: [0xB019Ae32a98fd206881f691fFe021A2B2520Ce9d]
- TON: [UQDWa0-nCyNM1jghk1PBRcjBt4Lxvs86wflNGHHQtxfyx-8J]

## License

Licensed under the MIT License - See [LICENSE](LICENSE) for details.